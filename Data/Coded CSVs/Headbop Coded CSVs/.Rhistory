type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
par(op)
x11()
op <- par(mfrow = c(1,2))
interaction.plot(data.old$vintage, data.old$winetype, data.old$rating,
xlab = "Year", ylab = "Rating", main = "Old World Interaction",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Red", "White"), col = 1:2, lty = 1, cex = 0.8)
interaction.plot(data.new$vintage, data.new$winetype, data.new$rating,
xlab = "Year", ylab = "Rating", main = "New World Interaction",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
par(op)
x11()
op <- par(mfrow = c(1,2))
interaction.plot(data.old$vintage, data.old$winetype, data.old$rating,
xlab = "Year", ylab = "Rating", main = "Old World Interaction",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Red", "White"), col = 1:2, lty = 1, cex = 0.8)
interaction.plot(data.new$vintage, data.new$winetype, data.new$rating,
xlab = "Year", ylab = "Rating", main = "New World Interaction",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Red", "White"), col = 1:2, lty = 1, cex = 0.8)
par(op)
x11()
op <- par(mfrow = c(1,2))
interaction.plot(Optim, Sex, Ratio,
xlab = "Optimist/Pessimist", ylab = "Ratio", main = "Interaction Sex|Optim",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomleft", legend = c("Male", "Female"), col = 1:2, lty = 1, cex = 0.8)
interaction.plot(Sex, Optim, Ratio,
xlab = "Sex", ylab = "Ratio", main = "Interaction Optim|Sex",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Optimists", "Pessimists"), col = 1:2, lty = 1, cex = 0.8)
par(op)
x11()
op <- par(mfrow = c(1,2))
interaction.plot(winetype, world, rating,
xlab = "Wine Type", ylab = "Rating", main = "Interaction World|WineType",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomleft", legend = c("Old", "New"), col = 1:2, lty = 1, cex = 0.8)
interaction.plot(world, winetype, rating,
xlab = "Wolrd", ylab = "Rating", main = "Interaction WineType|World",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Red", "White"), col = 1:2, lty = 1, cex = 0.8)
par(op)
fitaov_op <- aov(Ratio ~ Optim*Sex*Event, data = optpes, contrasts = contr.sum)   ## Type I SS
model.matrix(fitaov_op)
fitaov_op3 <- Anova(fitaov_op, type = "II")       ## calculating Type II SS
fitaov_op3
fitaov_op3
fitaov_3 <- aov(Rating ~ winetype*world*year, data = data, contrasts = contr.sum)   ## Type I SS
fitaov_3 <- aov(rating ~ winetype*world*year, data = data, contrasts = contr.sum)   ## Type I SS
model.matrix(fitaov_3)
fitaov_op3 <- Anova(fitaov_3, type = "II")       ## calculating Type II SS
fitaov_op3
View(data)
source('~/Desktop/CLide_Pset3_PSY1950.R')
ratings <- as.matrix(winedat[,2:5])
ratings
mlm <- lm(ratings ~ 1)
mlm
yearratings <- factor(c("2010", "2011", "2012", "2013"))
yearratings
fitaovratings <- Anova(mlm, idata = data.frame(yearratings), idesign = ~ yearratings, type = "III")
summary(fitaovratings, multivariate = FALSE)
x11()
op <- par(mfrow = c(1,2))
interaction.plot(data.old$vintage, data.old$winetype, data.old$rating,
xlab = "Year", ylab = "Rating", main = "Old World Interaction",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Red", "White"), col = 1:2, lty = 1, cex = 0.8)
interaction.plot(data.new$vintage, data.new$winetype, data.new$rating,
xlab = "Year", ylab = "Rating", main = "New World Interaction",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Red", "White"), col = 1:2, lty = 1, cex = 0.8)
par(op)
x11()
op <- par(mfrow = c(1,2))
interaction.plot(winetype, world, rating,
xlab = "Wine Type", ylab = "Rating", main = "Interaction World|WineType",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomleft", legend = c("Old", "New"), col = 1:2, lty = 1, cex = 0.8)
interaction.plot(world, winetype, rating,
xlab = "Wolrd", ylab = "Rating", main = "Interaction WineType|World",
type = "b", pch = 19, lty = 1, col = 1:2, legend = FALSE)
legend("bottomright", legend = c("Red", "White"), col = 1:2, lty = 1, cex = 0.8)
par(op)
source('~/Desktop/CLide_Pset3_PSY1950.R')
if (!require(compute.es)) {install.packages("compute.es"); require(compute.es)}  ## effect size package
if (!require(effsize)) {install.packages("effsize"); require(effsize)}           ## another effect size package
if (!require(lsr)) {install.packages("lsr"); require(lsr)}                       ## some effects size tools
if (!require(pwr)) {install.packages("pwr"); require(pwr)}                       ## package for power calculation
if (!require(samplesize)) {install.packages("samplesize"); require(samplesize)}  ## package for optimal sample size calculation
if (!require(PairedData)) {install.packages("PairedData"); require(PairedData)}  ## paired datasets
if (!require(lm.beta)) {install.packages("lm.beta"); require(lm.beta)}           ## standardized regression coefficients
if (!require(mvtnorm)) {install.packages("mvtnorm"); require(mvtnorm)}           ## simulating from multivariate normal
require(foreign)
require(MASS)
require(ez)
require(car)
require(reshape)
require(rgl)
?readChar
if (!require(tm)) install.packages("tm"); require(tm)
if (!require(wordcloud)) install.packages("wordcloud"); require(wordcloud)
posting1 <- 'Facebook Job Application Descriptions.docx'
job1<- readChar(posting1)
posting1 <- readDOC("Facebook Job Application Descriptions.docx")
job1<- readChar(posting1)
?file.info
job1<- readChar(posting1, file.info('posting1')$size)
?posting1
class(posting1)
View(posting1)
View(posting1)
posting1
posting1 <- readPDF("Facebook Job Application Descriptions.pdf")
posting1 <- readPlain("Facebook Job Application Descriptions.docx")
posting1 <- readPlain("Facebook Job Application Descriptions.docx")
LinkedInRaw <- htmlParse("https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs")
??htmlParse
if (!require(XML)) {install.packages("XML"); require(XML)}
if (!require(tm)) {install.packages("tm"); require(tm)}
LinkedInRaw <- htmlParse("https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs")
if (!require(RCurl)) {install.packages("RCurl"); require(RCurl)}
LinkedInRaw <- getURL("https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs")
?xpathApply
descriptionpages <- xpathApply(LinkedInRaw, "https://www.linkedin.com/jobs2/view/")
descriptionpages <- xpathApply(LinkedInRaw, "jobs2/view/")
facultyHTML <- htmlParse("http://www.isites.harvard.edu/icb/icb.do?keyword=k3007&pageid=icb.page18831")
class(facultyHTML)
class(LinkedInRaw)
LinkedInRaw <- htmlParse("https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs")
LinkedInRaw <- getURL("https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs")
parsed <- htmlTreeParse(LinkedInRaw)
LinkedInRaw <- getURL("https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs", ssl.verifypeer = FALSE)
parsed <- htmlTreeParse(LinkedInRaw)
?ssl.verifypeer
??ssl.verifypeer
if (!require(scrapeR)) {install.packages("scrapeR"); require(scrapeR)}
?scrapeR
library(scrapeR)
pageSource <- scrape(url="https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs",headers=TRUE,
pageSource <- scrape(url="https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs",headers=TRUE,
parse=FALSE)
pageSource <- scrape(url="https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs",headers=TRUE, parse=FALSE)
pageSource <- scrape(url="https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs", headers=TRUE, parse=FALSE)
dim(pageSource)
pageSource <- scrape(url="https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs", headers=TRUE, parse=FALSE)
source('~/Desktop/CLide_PSY1950_Pset4.R')
source('~/Desktop/CLide_PSY1950_Pset4.R')
if (!require(ngramr)) install.packages("ngramr"); require(ngramr)
?ngramr
if(!require(rjson)) install.packages("rjson"); require(rjson)
if (!require(plyr)) install.packages("plyr"); require(plyr)
if(!require(rvest)) install.packages("rvest"); require(rvest)
furl <- 'http://www.isites.harvard.edu/icb/icb.do?keyword=k3007&pageid=icb.page18831'
# let's browse to that page
browseURL(furl)
site <- 'http://jobs.businessweek.com/a/all-jobs/list'
browseURL(site)
raw <- read_html(site)
browseURL(furl)
browseURL(furl)
site <- 'https://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs'
browseURL(site)
raw <- read_html(site)
site <- 'http://www.linkedin.com/job/home?trk=nav_responsive_sub_nav_jobs'
browseURL(site)
raw <- read_html(site)
site <- 'http://jobs.businessweek.com/a/all-jobs/list'
browseURL(site)
raw <- read_html(site)
jobs <- raw %>%
html_nodes("ul#sh_results")
furl <- 'http://www.isites.harvard.edu/icb/icb.do?keyword=k3007&pageid=icb.page18831'
browseURL(furl)
facultydir <- read_html(furl)
divwraps <- facultydir %>%
html_nodes("div.wrap")
divwraps
jobpage <- jobs %>%
html_text()
jobpage
joblinks <- jobs[2] %>%
html_nodes("a target") %>%
html_attr("href")
jobs <- raw %>%
html_nodes("ul#sh_results")
jobpage <- jobs %>%
html_text()
jobpage
# Let's extract the links
joblinks <- jobs[2] %>%
html_nodes("a target") %>%
html_attr("href")
links <- jobs[2] %>%
html_nodes("a") %>%
html_attr("href")
?html_nodes
html_nodes(links, "a") %>%
html_attr("href")
links <- jobs[2] %>%
html_nodes(links, "a") %>%
html_attr("href")
links <- jobs[2] %>%
html_nodes(links, "a")
links <- jobs[2] %>%
html_nodes("a")
links <- jobs[2] %>%
html_nodes("a") %>%
html_attr("href")
links <- jobs[2] %>%
html_nodes("a") %>%
html_attr("href") %>%
links <- jobs[2] %>%
html_nodes("a") %>%
html_attr("href") %>%
?html_attr
?html_attr
links <- jobs[2] %>%
node <- html_nodes("a") %>%
html_attr(node, "href")
?xml_find_all
links <- jobs[3] %>%
html_nodes("a") %>%
html_attr("href")
descriptions <- jobs[6] %>%
descriptions <- jobs[6]
descriptions <- jobs[6]
jobs <- raw %>%
html_nodes("ul#sh_results")
jobpage <- jobs %>%
html_text()
jobpage
descriptions <- jobs[6]
html_nodes("a") %>%
html_attr("href")
links <- jobs[3]
html_nodes("a") %>%
html_attr("href")
site <- 'http://www.careerbuilder.com/browse/?sc_cmp2=JS_Nav_FindJobs'
browseURL(site)
raw <- read_html(site)
raw <- read_html(site)
industries <- raw %>%
html_nodes("tbody")
site <- 'http://www.careerbuilder.com/browse/?sc_cmp2=JS_Nav_FindJobs'
browseURL(site)
raw <- read_html(site)
industries <- raw %>%
html_nodes("tbody")
jobs <- industries %>%
html_text()
jobs
industries <- raw %>%
html_nodes("table")
jobs <- industries %>%
html_text()
jobs
industries <- raw %>%
html_nodes("td")
jobs <- industries %>%
html_text()
jobs
industries <- raw %>%
html_nodes("table")
jobs <- industries %>%
html_text()
jobs
links <- jobs[4]
html_nodes("a#TitleLinks") %>%
html_attr("href")
links <- jobs[4]
html_nodes("a") %>%
html_attr("href")
industries <- raw %>%
html_nodes("tr")
jobs <- industries %>%
html_text()
jobs
industries <- raw %>%
html_nodes("table#BodyLinks.fullWidthTable")
jobs <- industries %>%
html_text()
jobs
links <- jobs[4]
html_nodes("a") %>%
html_attr("href")
jobs <- industries %>%
html_text()
jobs
# Let's extract the links
links <- jobs[8]
html_nodes("a") %>%
html_attr("href")
?UseMethod("xml_find_all")
if(!require(twitteR)) install.packages("twitteR"); require(twitteR)
if(!require(pracma)) install.packages("pracma"); require(pracma)
if(!require(igraph)) install.packages("igraph"); require(igraph)
if(!require(qdap)) install.packages("qdap"); require(qdap)
if(!require(rvest)) install.packages("rvest"); require(rvest)
if (!require(tm)) install.packages("tm"); require(tm)
if (!require(anacor)) install.packages("anacor"); require(anacor)
if (!require(topicmodels)) {install.packages("topicmodels"); require(topicmodels)}
if (!require(rjson)) install.packages("rjson"); require(rjson)
jobs <- industries %>%
html_text()
jobs
# Let's extract the links
links <- jobs[8]
html_nodes("a") %>%
html_attr("href")
links <- jobs[8]
html_nodes("aTitleLink") %>%
html_attr("href")
site <- 'http://www.careerbuilder.com/jobs/keyword/accounting'
browseURL(site)
raw <- read_html(site)
raw <- read_html(site)
site <- 'http://www.careerbuilder.com/jobs/keyword/accounting'
raw <- read_html(site)
jobs <- raw %>%
html_nodes("div.columns.medium-10")
jobtitle <- jobs %>%
html_text()
jobtitle
links <- jobs[8]
html_nodes("aTitleLink") %>%
html_attr("href")
class(jobs)
class(jobtitle)
class(dirtext)
furl <- 'http://www.isites.harvard.edu/icb/icb.do?keyword=k3007&pageid=icb.page18831'
facultydir <- read_html(furl)
divwraps <- facultydir %>%
html_nodes("div.wrap")
# It looks like the 4th div.wrap is the one we want
dirtext <- divwraps %>%
html_text()
dirtext
class(dirtext)
links <- divwraps[4] %>%
html_nodes("a") %>%
html_attr("href")
class(links)
site <- 'http://jobs.businessweek.com/a/all-jobs/list'
raw <- read_html(site)
raw <- read_html(site)
jobs <- raw %>%
html_nodes("ul#sh_results")
jobtitle <- jobs %>%
html_text()
jobtitle
links <- jobs[6]
html_nodes("a") %>%
html_attr("href")
links <- jobs[6]
html_nodes("a") %>%
html_attrs("href")
site <- 'http://jobs.businessweek.com/a/all-jobs/list'
browseURL(site)
raw <- read_html(site)
jobs <- raw %>%
html_nodes("div.module.storyResults")
jobtitle <- jobs %>%
html_text()
jobtitle
# Let's extract the links
links <- jobs[3]
html_nodes("a") %>%
html_attrs("href")
%>%
?%>%
dirtext <- divwraps %>%
html_text()
dirtext
links <- divwraps[4] %>%
html_nodes("a") %>%
html_attr("href")
links <- jobs[3]
html_nodes("a") %>%
html_attr("href")
jobtitle <- jobs %>%
html_text()
jobtitle
if (!require(neuRosim)) install.packages("neuRosim"); require(neuRosim)
if (!require(signal)) install.packages("signal"); require(signal)
if (!require(fields)) install.packages("fields"); require(fields)
if (!require(spatstat)) install.packages("spatstat"); require(spatstat)
if (!require(matlab)) install.packages("matlab"); require(matlab)
if (!require(MSBVAR)) install.packages("MSBVAR"); require(MSBVAR)
if (!require(e1071)) install.packages("e1071"); require(e1071)
if (!require(fields)) install.packages("fields"); require(fields)
set.seed(625)
design <- simprepTemporal(totaltime=200, onsets=seq(1,200,20), durations=0.5, effectsize=1, TR=1, hrf="double-gamma")
ts <- simTSfmri(design=design, SNR=10, noise="white")
ts1 <- ts[seq(1,200,2)]
ts2 <- ts[seq(2,200,2)]
plot(ts1,type="o",xlab="TR (2s)",ylab="BOLD",main="Two slices (1s apart) of a simulated slow-event related timecourse",xlim=c(1,100))
points(ts2,type="o",col="blue")
abline(v=seq(1,200,20)/2,col="red")
ts2re <- resample(ts2,2)
ts2re <- ts2re[seq(2,200,2)]
ts2re <- c(0,ts2re[1:99])
points(ts2re,type="o",col="green")
gcent <- c(33,58)
area <- combn(c(-3:3,-3:3),2)
avnum <- max(dim(area))
truedat <- matrix(0,100,100)
sarea <- area+gcent
for (v in 1:avnum){
x <- sarea[1,v]
y <- sarea[2,v]
truedat[x,y] <- 1
}
puredat <- array(0,dim=c(100,100,10))
for (sub in 1:10){
scent <- gcent + c(sample(-8:8,size=2,replace=T))
sarea <- area+scent
for (v in 1:avnum){
x <- sarea[1,v]
y <- sarea[2,v]
puredat[x,y,sub] <- 1
}
}
noisedat <- puredat + array(rnorm(100*100*10,mean=0,sd=.5),dim=c(100,100,10))
x11()
layout(matrix(c(1:10), nrow=2))
rot <- function(x) t(apply(x,2,rev))
for (sub in 1:10){
image.plot(rot(noisedat[,,sub]),xlab="",ylab="",zlim=c(-2,2))
}
traw <- apply(noisedat,c(1,2),function(x) t.test(x)$statistic)
smoothdat <- noisedat
for (sub in 1:10){
smoothdat[,,sub] <- as.matrix(blur(as.im(smoothdat[,,sub]),sigma=8))
}
for (sub in 1:10){
smoothdat[,,sub] <- as.matrix(blur(as.im(smoothdat[,,sub]),sigma=8))
}
?blur
??blur
alldata <- data.frame(NULL)
# Create function to read in and merge all individual data sets
multmerge = function(mypath){
filenames=list.files(path=mypath, full.names=TRUE)
datalist = lapply(filenames, function(x){read.csv(file=x,header=T)})
Reduce(function(x,y) {merge(x,y)}, datalist)
alldata <- multmerge("/Users/cello72294/Desktop/TestData")
head(alldata)
multmerge = function(mypath){
filenames=list.files(path=mypath, full.names=TRUE)
datalist = lapply(filenames, function(x){read.csv(file=x,header=T)})
Reduce(function(x,y) {merge(x,y)}, datalist)
alldata <- multmerge ("/Users/cello72294/Desktop/TestData")
alldata <- data.frame(NULL)
multmerge = function(mypath){
filenames=list.files(path=mypath, full.names=TRUE)
datalist = lapply(filenames, function(x){read.csv(file=x,header=T)})
Reduce(function(x,y) {merge(x,y)}, datalist)}
alldata <- multmerge("/Users/cello72294/Desktop/TestData")
head(alldata)
source('~/Desktop/CLide_Headbop_Analysis.R')
mcdi <- c(33
33
2
54
5
8
NA
9
5
22
25
21
0
32
4
28
8
4
20
3)
mcdi <- as.vector(c(33, 33, 2, 54, 5, 8, 9, 5, 22, 25, 21, 0, 32, 4, 28, 8, 4, 20, 3))
mcditable <- as.table(mcdi)
mcditable
summary(mcdi)
boxplot(mcdi)
hist(mcdi)
load_data <- function(path) {
files <- dir(path, pattern = '\\.csv', full.names = TRUE)
tables <- lapply(files, read.csv)
do.call(rbind, tables)
}
alldata <- load_data("Headbop Coded CSVs")
head(alldata)
load_data <- function(path) {
files <- dir(path, pattern = '\\.csv', full.names = TRUE)
tables <- lapply(files, read.csv)
do.call(rbind, tables)
}
alldata <- load_data("Headbop Coded CSVs")
head(alldata)
setwd("/Users/cello72294/Desktop/Headbop Coded CSVs")
load_data <- function(path) {
files <- dir(path, pattern = '\\.csv', full.names = TRUE)
tables <- lapply(files, read.csv)
do.call(rbind, tables)
}
alldata <- load_data("Headbop Coded CSVs")
head(alldata)
